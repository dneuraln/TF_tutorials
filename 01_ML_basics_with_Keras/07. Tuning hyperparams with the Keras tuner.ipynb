{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08de18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1769542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960fd5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb3dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f120b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec5f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-10 13:22:24.350327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47220 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "2021-09-10 13:22:24.351874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46865 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6710b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a callback to stop training early after reaching a certain value for the validation loss.\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 Complete [00h 00m 59s]\n",
      "val_accuracy: 0.8924999833106995\n",
      "\n",
      "Best val_accuracy So Far: 0.8924999833106995\n",
      "Total elapsed time: 00h 11m 27s\n",
      "\n",
      "Search: Running Trial #30\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |288               |192               \n",
      "learning_rate     |0.0001            |0.001             \n",
      "tuner/epochs      |10                |10                \n",
      "tuner/initial_e...|0                 |0                 \n",
      "tuner/bracket     |0                 |0                 \n",
      "tuner/round       |0                 |0                 \n",
      "\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6744 - accuracy: 0.7817 - val_loss: 0.4905 - val_accuracy: 0.8334\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4575 - accuracy: 0.8452 - val_loss: 0.4596 - val_accuracy: 0.8403\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4138 - accuracy: 0.8576 - val_loss: 0.4190 - val_accuracy: 0.8550\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3884 - accuracy: 0.8658 - val_loss: 0.3894 - val_accuracy: 0.8651\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3685 - accuracy: 0.8726 - val_loss: 0.3899 - val_accuracy: 0.8604\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3537 - accuracy: 0.8755 - val_loss: 0.3718 - val_accuracy: 0.8679\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3414 - accuracy: 0.8800 - val_loss: 0.3648 - val_accuracy: 0.8717\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3296 - accuracy: 0.8835 - val_loss: 0.3551 - val_accuracy: 0.8766\n",
      "Epoch 9/10\n",
      " 747/1500 [=============>................] - ETA: 2s - loss: 0.3206 - accuracy: 0.8881"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c47cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a7b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ca086",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d534a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
