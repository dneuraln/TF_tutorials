{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9abe4b5-8070-4488-a989-04c737239796",
   "metadata": {},
   "source": [
    " We recommend using tf.keras as a high-level API for building neural networks. That said, most TensorFlow APIs are usable with eager execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5c3d06-989d-4414-ba56-8384c48b2f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_55735/1473334969.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 14:58:06.956395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 47220 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "2021-09-13 14:58:06.957910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 47030 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba364d31-6472-438b-9a16-32193f8d7126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the tf.keras.layers package, layers are objects. To construct a layer,\n",
    "# simply construct the object. Most layers take as a first argument the number\n",
    "# of output dimensions / channels.\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "# The number of input dimensions is often unnecessary, as it can be inferred\n",
    "# the first time the layer is used, but it can be provided if you want to\n",
    "# specify it manually, which is useful in some complex models.\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc03daab-7ee2-4d37-ae60-2214f3a995e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 14:58:06.995765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47220 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "2021-09-13 14:58:06.996927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 47030 MB memory:  -> device: 1, name: Quadro RTX 8000, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To use a layer, simply call it.\n",
    "layer(tf.zeros([10, 5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a99c8e-2492-459a-ad37-3d4cd552b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.01534688,  0.34512436, -0.372823  , -0.2847751 , -0.61375993,\n",
       "          0.23365611,  0.29695797, -0.19304237,  0.00221175, -0.44627392],\n",
       "        [-0.39554936,  0.6145453 , -0.17348278, -0.21842578,  0.30425632,\n",
       "         -0.6014203 ,  0.5933426 , -0.18207625,  0.35804147, -0.53580993],\n",
       "        [ 0.2895925 , -0.17872494,  0.19764715,  0.18876612, -0.51273227,\n",
       "          0.2713027 ,  0.62135357, -0.47663015, -0.6000725 ,  0.08501625],\n",
       "        [-0.42267406, -0.3493946 , -0.35278252, -0.34475857,  0.04695481,\n",
       "          0.6275155 ,  0.16112196, -0.14865443, -0.07142568, -0.6131105 ],\n",
       "        [ 0.42799097,  0.47907072, -0.03189659, -0.05419332, -0.39991003,\n",
       "         -0.20703214, -0.23198143,  0.23511255, -0.0358637 ,  0.01513577]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Layers have many useful methods. For example, you can inspect all variables\n",
    "# in a layer using `layer.variables` and trainable variables using\n",
    "# `layer.trainable_variables`. In this case a fully-connected layer\n",
    "# will have variables for weights and biases.\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d64e52-64c5-46cd-a4be-3074a4291f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[-0.01534688,  0.34512436, -0.372823  , -0.2847751 , -0.61375993,\n",
       "          0.23365611,  0.29695797, -0.19304237,  0.00221175, -0.44627392],\n",
       "        [-0.39554936,  0.6145453 , -0.17348278, -0.21842578,  0.30425632,\n",
       "         -0.6014203 ,  0.5933426 , -0.18207625,  0.35804147, -0.53580993],\n",
       "        [ 0.2895925 , -0.17872494,  0.19764715,  0.18876612, -0.51273227,\n",
       "          0.2713027 ,  0.62135357, -0.47663015, -0.6000725 ,  0.08501625],\n",
       "        [-0.42267406, -0.3493946 , -0.35278252, -0.34475857,  0.04695481,\n",
       "          0.6275155 ,  0.16112196, -0.14865443, -0.07142568, -0.6131105 ],\n",
       "        [ 0.42799097,  0.47907072, -0.03189659, -0.05419332, -0.39991003,\n",
       "         -0.20703214, -0.23198143,  0.23511255, -0.0358637 ,  0.01513577]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The variables are also accessible through nice accessors\n",
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b220069-e9aa-45ec-b799-37e7517c515a",
   "metadata": {},
   "source": [
    "# Implementing custom layers\n",
    "\n",
    "The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n",
    "\n",
    "1. `__init__` , where you can do all input-independent initialization\n",
    "2. `build`, where you know the shapes of the input tensors and can do the rest of the initialization\n",
    "3. `call`, where you do the forward computation\n",
    "\n",
    "The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n",
    "\n",
    "`__init__` , where you can do all input-independent initialization\n",
    "`build`, where you know the shapes of the input tensors and can do the rest of the initialization\n",
    "`call`, where you do the forward computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76d36dc-75d3-46a5-94fe-73f5a3d8dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\"kernel\", shape=[int(input_shape[-1]),self.num_outputs])\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "layer = MyDenseLayer(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "996eae99-7ae8-4f4c-a30e-16bff90924a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = layer(tf.zeros([10,5])) # Calling the layer `.build` it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc8c326c-9057-4529-8739-e23029775edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32, numpy=\n",
       " array([[ 0.0806933 , -0.4017154 , -0.6069063 , -0.5681298 ,  0.49773973,\n",
       "          0.31076634, -0.12566888, -0.21063569, -0.23032513,  0.6061987 ],\n",
       "        [ 0.5216983 , -0.13967675, -0.08414078,  0.3906197 ,  0.58681303,\n",
       "          0.31447816,  0.55978507, -0.28450835,  0.35210836, -0.45621485],\n",
       "        [ 0.37886244, -0.2424385 ,  0.42914182, -0.1308096 , -0.4745692 ,\n",
       "         -0.4131187 ,  0.54800016,  0.6166344 , -0.04604906, -0.34854805],\n",
       "        [ 0.12049365,  0.05217397,  0.50509113, -0.32839978, -0.06425399,\n",
       "          0.05908597, -0.5702238 , -0.27301475,  0.43216723, -0.6230164 ],\n",
       "        [ 0.14170712, -0.26493338,  0.19611198,  0.40088254,  0.1663934 ,\n",
       "          0.21620196,  0.38526446, -0.17311695,  0.3387335 , -0.18019363]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7966741a-29f2-4445-99e3-8a3ff3b8f21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my_dense_layer/kernel:0']\n"
     ]
    }
   ],
   "source": [
    "print([var.name for var in layer.trainable_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7951a1-a24b-4526-8b67-7fe24198e819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 3, 10) dtype=float32, numpy=\n",
       " array([[[[ 0.08549304,  0.00463147,  0.20995446,  0.14259551,\n",
       "           -0.22436622,  0.18535177,  0.22405832,  0.05308171,\n",
       "            0.19166662,  0.20431288],\n",
       "          [-0.20619413,  0.20676379,  0.11455102, -0.15163179,\n",
       "            0.03282215,  0.04949506,  0.2218485 ,  0.21412496,\n",
       "            0.13070647,  0.02548058],\n",
       "          [ 0.19759716,  0.21367516, -0.06055786, -0.09299877,\n",
       "           -0.00755154,  0.09653433, -0.07846721, -0.119426  ,\n",
       "           -0.21250057, -0.00655372]],\n",
       " \n",
       "         [[-0.16264641,  0.09843038, -0.00997697,  0.13627239,\n",
       "            0.12827678, -0.09802169, -0.13522354, -0.12958649,\n",
       "            0.1686626 , -0.15718603],\n",
       "          [ 0.00630628, -0.05486156,  0.18916242,  0.05059217,\n",
       "            0.16535331, -0.09154329,  0.13618474,  0.2094361 ,\n",
       "            0.11571838, -0.14504044],\n",
       "          [-0.12885422,  0.20255686,  0.18671818, -0.00268261,\n",
       "            0.21465905,  0.1893395 , -0.03817926,  0.08273484,\n",
       "            0.0535862 ,  0.18905918]],\n",
       " \n",
       "         [[-0.08675259,  0.220894  ,  0.0047583 , -0.11701033,\n",
       "           -0.17440785,  0.10943203, -0.14206514,  0.17012323,\n",
       "            0.04359896, -0.05019425],\n",
       "          [ 0.12446441, -0.18829747, -0.08956121,  0.06764586,\n",
       "           -0.0686602 ,  0.09217001, -0.04524827, -0.03499454,\n",
       "           -0.00418805,  0.0320646 ],\n",
       "          [ 0.10941802, -0.06386244, -0.01095259, -0.12721547,\n",
       "            0.18573402, -0.06990832, -0.02354226, -0.1103409 ,\n",
       "           -0.21563098, -0.09090024]]],\n",
       " \n",
       " \n",
       "        [[[-0.15824705, -0.03232802, -0.10506877, -0.02448241,\n",
       "            0.20988826,  0.19973733, -0.08903296,  0.05100386,\n",
       "           -0.0988653 , -0.1040234 ],\n",
       "          [-0.19535384, -0.08333446, -0.20009491,  0.16984181,\n",
       "            0.14641424,  0.21199895,  0.07427265, -0.13846594,\n",
       "            0.14326327, -0.11067101],\n",
       "          [-0.08757806, -0.20011112,  0.08288287,  0.12340035,\n",
       "            0.11859809, -0.15527959,  0.05623256, -0.06575401,\n",
       "            0.20667605,  0.09119131]],\n",
       " \n",
       "         [[ 0.02596845, -0.07252246, -0.2041069 , -0.19777659,\n",
       "            0.15658055,  0.13748233,  0.17745496, -0.153561  ,\n",
       "           -0.18165822, -0.12229822],\n",
       "          [-0.07769778,  0.15755455,  0.05074988, -0.08723916,\n",
       "           -0.04966249,  0.01048061, -0.18385285,  0.01111953,\n",
       "            0.1164154 ,  0.00465733],\n",
       "          [-0.03671081, -0.03909825,  0.02067754,  0.02328564,\n",
       "           -0.09055136,  0.04910345, -0.03622068,  0.22611521,\n",
       "           -0.13363102, -0.20477292]],\n",
       " \n",
       "         [[ 0.14471854, -0.1287161 ,  0.13140653, -0.08579376,\n",
       "            0.03190847,  0.21045734,  0.03928505,  0.14620589,\n",
       "            0.22150593, -0.05837066],\n",
       "          [ 0.12220483,  0.01783663,  0.01395564, -0.0860019 ,\n",
       "            0.00098188,  0.03940542, -0.09943183, -0.07624833,\n",
       "           -0.08766542, -0.04709834],\n",
       "          [ 0.02130389,  0.12798996, -0.1521331 ,  0.14802136,\n",
       "            0.21275471, -0.20303036, -0.13141868, -0.17775185,\n",
       "           -0.05952446, -0.10896801]]],\n",
       " \n",
       " \n",
       "        [[[-0.03508039, -0.13409933,  0.21459834, -0.12782994,\n",
       "           -0.0632337 ,  0.2160802 ,  0.00675036,  0.20336895,\n",
       "            0.22540529,  0.16003059],\n",
       "          [ 0.0744931 ,  0.0920767 , -0.2104663 , -0.0788655 ,\n",
       "            0.04468794,  0.16829239, -0.19049026,  0.15202333,\n",
       "            0.03610472,  0.19167538],\n",
       "          [-0.03171813,  0.09514795,  0.12286605,  0.08102094,\n",
       "            0.07098003, -0.0317663 , -0.09720582, -0.20454967,\n",
       "           -0.08682683, -0.21442465]],\n",
       " \n",
       "         [[-0.15842609, -0.07803538,  0.11995988, -0.10793587,\n",
       "           -0.00976782,  0.21190111, -0.16863242,  0.07669933,\n",
       "           -0.01650186,  0.09375022],\n",
       "          [ 0.05666213,  0.10562851, -0.00665192, -0.18926293,\n",
       "            0.13385601,  0.09505974, -0.21642163, -0.0424328 ,\n",
       "            0.14770465,  0.19488947],\n",
       "          [ 0.14225422, -0.01924747,  0.09427048,  0.12470029,\n",
       "           -0.20314725,  0.08192103,  0.17574267,  0.01452632,\n",
       "           -0.02551596,  0.0795954 ]],\n",
       " \n",
       "         [[ 0.07132198, -0.00556228,  0.06667332,  0.09330668,\n",
       "           -0.14603162,  0.01826359,  0.18220817, -0.14772692,\n",
       "            0.0849738 ,  0.08047666],\n",
       "          [ 0.02215084,  0.08006351,  0.06235678, -0.12847838,\n",
       "            0.11458768, -0.05166966,  0.1632766 ,  0.17817087,\n",
       "            0.04268099,  0.11307792],\n",
       "          [ 0.05821399, -0.21129765, -0.10617262,  0.06619616,\n",
       "            0.14081551,  0.09012975,  0.13521145,  0.15894182,\n",
       "           -0.07906349, -0.07421622]]]], dtype=float32)>,\n",
       " <tf.Variable 'conv2d_2/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for convolutional networks\n",
    "convlayer = tf.keras.layers.Conv2D(10,(3,3))\n",
    "_ = convlayer(tf.zeros([10,32,32,3]))\n",
    "convlayer.variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2bde1-1f24-4e90-9412-e34ff4169922",
   "metadata": {},
   "source": [
    "### Models: Composing layers\n",
    "\n",
    "Many interesting layer-like things in machine learning models are implemented by composing existing layers. For example, each residual block in a resnet is a composition of convolutions, batch normalizations, and a shortcut. Layers can be nested inside other layers.\n",
    "\n",
    "Typically you inherit from keras.Model when you need the model methods like: Model.fit,Model.evaluate, and Model.save (see Custom Keras layers and models for details).\n",
    "\n",
    "One other feature provided by keras.Model (instead of keras.layers.Layer) is that in addition to tracking variables, a keras.Model also tracks its internal layers, making them easier to inspect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0375543-1404-44ee-b2b6-80f6ed2c2c88",
   "metadata": {},
   "source": [
    "# ResNet block:\n",
    "\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b0725-9751-4d7c-8944-2d8776856de2",
   "metadata": {},
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1cb5aa4b-0e96-4947-86fa-be77db5213a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "  def __init__(self, kernel_size, filters):\n",
    "    super(ResnetIdentityBlock, self).__init__(name='')\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "    self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "    self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "    self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "  def call(self, input_tensor, training=False):\n",
    "    x = self.conv2a(input_tensor)\n",
    "    x = self.bn2a(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2b(x)\n",
    "    x = self.bn2b(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    x = self.conv2c(x)\n",
    "    x = self.bn2c(x, training=training)\n",
    "\n",
    "    x += input_tensor\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed7bd4f9-826e-46e9-8e0a-72d6926f3f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = block(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48670cb-2cb1-44fc-bcbe-9f22286c1921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x7f7f68238520>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f7e665eeeb0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f7e66587220>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f7e665876a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f7e66587a00>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f7e66587eb0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f5120f-af83-442a-bb3e-cd49f15519de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7de1f71b-1743-4696-b44c-60c8fe3d11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchN  multiple                  4         \n",
      "ormalization)                                                    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            multiple                  4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batc  multiple                  8         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            multiple                  9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batc  multiple                  12        \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5bd40-ef88-4e6e-bb0f-df893676a05b",
   "metadata": {},
   "source": [
    "### Much of the time, however, models which compose many layers simply call one layer after the other. This can be done in very little code using tf.keras.Sequential:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f48a615-29b2-4268-8f34-9f4af7953df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 3, 3), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1),\n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f309b55-f4b1-4ec7-93c0-47174fda14cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batc  (None, None, None, 1)     4         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 2)     4         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batc  (None, None, None, 2)     8         \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 3)     9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batc  (None, None, None, 3)     12        \n",
      "hNormalization)                                                  \n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 29\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_seq.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203039c4-2080-4ee3-b31b-27cc9077226d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
